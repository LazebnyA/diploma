Device: cuda

Neural Network Architecture:
ResNet_BiLSTM_CTC(
  (cnn): Sequential(
    (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Identity()
    )
    (4): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Identity()
    )
    (5): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    (6): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Identity()
    )
    (8): MaxPool2d(kernel_size=2, stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    (9): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Identity()
    )
    (11): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)
    (12): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): ResidualBlock(
      (conv_path): Sequential(
        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Identity()
    )
    (14): Identity()
  )
  (lstm): LSTM(1536, 512, num_layers=2, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=1024, out_features=80, bias=True)
)

Hyperparameters:
img_height: 64
num_channels: 1
n_classes: 80
n_h: 512
optimizer: RMSprop (
Parameter Group 0
    alpha: 0.99
    capturable: False
    centered: False
    differentiable: False
    eps: 1e-08
    foreach: None
    lr: 0.0001
    maximize: False
    momentum: 0
    weight_decay: 0
)
learning_rate: 0.0001
criterion: CTCLoss()
num_epochs: 10
batch_size: 16
transform: Resize with aspect ratio. Simple Transform
dataset: IAM Lines Dataset (writer-independent split). Cleaned dataset
Starting training process: 


Epoch 1 Results:
Training - Loss: 1.7032, CER: 0.5493, WER: 0.6988
Validation - Loss: 0.8311, CER: 0.2576, WER: 0.5118

Epoch 2 Results:
Training - Loss: 0.6764, CER: 0.2056, WER: 0.4427
Validation - Loss: 0.6209, CER: 0.1885, WER: 0.4274

Epoch 3 Results:
Training - Loss: 0.5027, CER: 0.1516, WER: 0.3628
Validation - Loss: 0.5360, CER: 0.1601, WER: 0.3906

Epoch 4 Results:
Training - Loss: 0.4065, CER: 0.1248, WER: 0.3161
Validation - Loss: 0.4706, CER: 0.1379, WER: 0.3502

Epoch 5 Results:
Training - Loss: 0.3386, CER: 0.1063, WER: 0.2807
Validation - Loss: 0.4669, CER: 0.1305, WER: 0.3379

Epoch 6 Results:
Training - Loss: 0.2858, CER: 0.0923, WER: 0.2527
Validation - Loss: 0.4426, CER: 0.1271, WER: 0.3292

Epoch 7 Results:
Training - Loss: 0.2386, CER: 0.0797, WER: 0.2266
Validation - Loss: 0.5320, CER: 0.1540, WER: 0.3759

Epoch 8 Results:
Training - Loss: 0.2010, CER: 0.0704, WER: 0.2073
Validation - Loss: 0.4369, CER: 0.1178, WER: 0.3165

Epoch 9 Results:
Training - Loss: 0.1686, CER: 0.0621, WER: 0.1882
Validation - Loss: 0.4889, CER: 0.1265, WER: 0.3316

Epoch 10 Results:
Training - Loss: 0.1427, CER: 0.0554, WER: 0.1732
Validation - Loss: 0.4590, CER: 0.1133, WER: 0.3054
Model saved as cnn_lstm_ctc_handwritten_v0_word_10ep_CNN-BiLSTM-CTC_CNN_V0.pth
Time elapsed: 4424.682679653168
Start time: 1745494333.3463137
End time: 1745498758.0289934
