Device: cuda
Loaded initial random weights from cnn_lstm_ctc_handwritten_v0_initial_imH64.pth

Neural Network Architecture:
CNN_LSTM_CTC_V2_CNN_more_filters_batch_norm_more_imH(
  (cnn): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)
  )
  (lstm): LSTM(2048, 256, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=512, out_features=80, bias=True)
)

Hyperparameters:
img_height: 64
num_channels: 1
n_classes: 80
n_h: 256
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
learning_rate: 0.001
criterion: CTCLoss()
num_epochs: 30
batch_size: 8
transform: Resize with aspect ratio. Median/Gaussian filter for noise removal
dataset: IAM Lines Dataset (writer-independent split)
Starting training process: 


Epoch 1 Results:
Training - Loss: 1.6190, CER: 0.4966, WER: 0.7159
Validation - Loss: 0.9848, CER: 0.2879, WER: 0.5623

Epoch 2 Results:
Training - Loss: 0.7584, CER: 0.2297, WER: 0.4874
Validation - Loss: 0.7662, CER: 0.2206, WER: 0.4687

Epoch 3 Results:
Training - Loss: 0.5660, CER: 0.1728, WER: 0.4060
Validation - Loss: 0.7083, CER: 0.1950, WER: 0.4292

Epoch 4 Results:
Training - Loss: 0.4509, CER: 0.1423, WER: 0.3545
Validation - Loss: 0.6629, CER: 0.1785, WER: 0.4116

Epoch 5 Results:
Training - Loss: 0.3654, CER: 0.1206, WER: 0.3145
Validation - Loss: 0.6835, CER: 0.1779, WER: 0.4112

Epoch 6 Results:
Training - Loss: 0.2924, CER: 0.1032, WER: 0.2796
Validation - Loss: 0.6961, CER: 0.1770, WER: 0.4127

Epoch 7 Results:
Training - Loss: 0.2336, CER: 0.0890, WER: 0.2499
Validation - Loss: 0.7383, CER: 0.1774, WER: 0.4134

Epoch 8 Results:
Training - Loss: 0.1873, CER: 0.0777, WER: 0.2266
Validation - Loss: 0.7852, CER: 0.1769, WER: 0.4136

Epoch 9 Results:
Training - Loss: 0.1515, CER: 0.0688, WER: 0.2063
Validation - Loss: 0.8294, CER: 0.1777, WER: 0.4125

Epoch 10 Results:
Training - Loss: 0.1257, CER: 0.0621, WER: 0.1921
Validation - Loss: 0.8621, CER: 0.1774, WER: 0.4124

Epoch 11 Results:
Training - Loss: 0.1061, CER: 0.0571, WER: 0.1798
Validation - Loss: 0.9135, CER: 0.1794, WER: 0.4147

Epoch 12 Results:
Training - Loss: 0.0914, CER: 0.0535, WER: 0.1717
Validation - Loss: 0.9572, CER: 0.1762, WER: 0.4120

Epoch 13 Results:
Training - Loss: 0.0810, CER: 0.0507, WER: 0.1653
Validation - Loss: 0.9778, CER: 0.1762, WER: 0.4126

Epoch 14 Results:
Training - Loss: 0.0739, CER: 0.0489, WER: 0.1614
Validation - Loss: 1.0364, CER: 0.1789, WER: 0.4182

Epoch 15 Results:
Training - Loss: 0.0661, CER: 0.0461, WER: 0.1536
Validation - Loss: 1.0492, CER: 0.1769, WER: 0.4164

Epoch 16 Results:
Training - Loss: 0.0613, CER: 0.0451, WER: 0.1513
Validation - Loss: 1.0910, CER: 0.1766, WER: 0.4148

Epoch 17 Results:
Training - Loss: 0.0580, CER: 0.0436, WER: 0.1477
Validation - Loss: 1.1224, CER: 0.1799, WER: 0.4165

Epoch 18 Results:
Training - Loss: 0.0547, CER: 0.0426, WER: 0.1459
Validation - Loss: 1.1663, CER: 0.1791, WER: 0.4174

Epoch 19 Results:
Training - Loss: 0.0527, CER: 0.0423, WER: 0.1446
Validation - Loss: 1.1646, CER: 0.1787, WER: 0.4163

Epoch 20 Results:
Training - Loss: 0.0510, CER: 0.0417, WER: 0.1441
Validation - Loss: 1.1873, CER: 0.1784, WER: 0.4161

Epoch 21 Results:
Training - Loss: 0.0480, CER: 0.0417, WER: 0.1451
Validation - Loss: 1.1908, CER: 0.1798, WER: 0.4166

Epoch 22 Results:
Training - Loss: 0.0487, CER: 0.0407, WER: 0.1409
Validation - Loss: 1.2664, CER: 0.1818, WER: 0.4270

Epoch 23 Results:
Training - Loss: 0.0463, CER: 0.0397, WER: 0.1376
Validation - Loss: 1.2508, CER: 0.1808, WER: 0.4224

Epoch 24 Results:
Training - Loss: 0.0468, CER: 0.0403, WER: 0.1405
Validation - Loss: 1.2513, CER: 0.1803, WER: 0.4211

Epoch 25 Results:
Training - Loss: 0.0420, CER: 0.0385, WER: 0.1354
Validation - Loss: 1.2867, CER: 0.1787, WER: 0.4162

Epoch 26 Results:
Training - Loss: 0.0420, CER: 0.0386, WER: 0.1351
Validation - Loss: 1.2800, CER: 0.1792, WER: 0.4168

Epoch 27 Results:
Training - Loss: 0.0417, CER: 0.0381, WER: 0.1338
Validation - Loss: 1.3300, CER: 0.1863, WER: 0.4319

Epoch 28 Results:
Training - Loss: 0.0414, CER: 0.0399, WER: 0.1391
Validation - Loss: 1.3191, CER: 0.1814, WER: 0.4207

Epoch 29 Results:
Training - Loss: 0.0403, CER: 0.0371, WER: 0.1317
Validation - Loss: 1.3554, CER: 0.1823, WER: 0.4206

Epoch 30 Results:
Training - Loss: 0.0411, CER: 0.0376, WER: 0.1329
Validation - Loss: 1.3666, CER: 0.1827, WER: 0.4243
Model saved as cnn_lstm_ctc_handwritten_v0_lines_30ep_CNN-BiLSTM-CTC_CNN-VGG16_BiLSTM-1dim.pth
Time elapsed: 26152.57810807228
Start time: 1744773613.964339
End time: 1744799766.542447
