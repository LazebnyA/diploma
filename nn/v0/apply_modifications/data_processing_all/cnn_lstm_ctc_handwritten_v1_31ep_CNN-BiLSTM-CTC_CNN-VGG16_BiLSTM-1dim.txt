Device: cuda
Loaded initial random weights from cnn_lstm_ctc_handwritten_v0_initial_imH64.pth

Neural Network Architecture:
CNN_LSTM_CTC_V2_CNN_more_filters_batch_norm_more_imH(
  (cnn): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)
  )
  (lstm): LSTM(2048, 256, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=512, out_features=80, bias=True)
)

Hyperparameters:
img_height: 64
num_channels: 1
n_classes: 80
n_h: 256
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
learning_rate: 0.001
criterion: CTCLoss()
num_epochs: 30
batch_size: 8
transform: Resize with aspect ratio. All transformations: brightness/contrast regulation, Otsu binarization, noise reduction
dataset: IAM Lines Dataset (writer-independent split)
Starting training process: 


Epoch 1 Results:
Training - Loss: 1.9022, CER: 0.5905, WER: 0.7786
Validation - Loss: 1.2700, CER: 0.3901, WER: 0.6533

Epoch 2 Results:
Training - Loss: 0.9423, CER: 0.3024, WER: 0.5670
Validation - Loss: 0.9446, CER: 0.2821, WER: 0.5316

Epoch 3 Results:
Training - Loss: 0.7005, CER: 0.2259, WER: 0.4681
Validation - Loss: 0.8518, CER: 0.2460, WER: 0.4880

Epoch 4 Results:
Training - Loss: 0.5577, CER: 0.1847, WER: 0.4064
Validation - Loss: 0.8209, CER: 0.2342, WER: 0.4783

Epoch 5 Results:
Training - Loss: 0.4491, CER: 0.1565, WER: 0.3617
Validation - Loss: 0.8152, CER: 0.2252, WER: 0.4667

Epoch 6 Results:
Training - Loss: 0.3568, CER: 0.1330, WER: 0.3204
Validation - Loss: 0.8513, CER: 0.2215, WER: 0.4660

Epoch 7 Results:
Training - Loss: 0.2844, CER: 0.1157, WER: 0.2899
Validation - Loss: 0.8815, CER: 0.2258, WER: 0.4692

Epoch 8 Results:
Training - Loss: 0.2231, CER: 0.0983, WER: 0.2578
Validation - Loss: 0.9497, CER: 0.2227, WER: 0.4684

Epoch 9 Results:
Training - Loss: 0.1800, CER: 0.0855, WER: 0.2341
Validation - Loss: 1.0232, CER: 0.2300, WER: 0.4796

Epoch 10 Results:
Training - Loss: 0.1481, CER: 0.0763, WER: 0.2166
Validation - Loss: 1.0783, CER: 0.2302, WER: 0.4797

Epoch 11 Results:
Training - Loss: 0.1250, CER: 0.0684, WER: 0.2011
Validation - Loss: 1.1412, CER: 0.2307, WER: 0.4776

Epoch 12 Results:
Training - Loss: 0.1067, CER: 0.0632, WER: 0.1910
Validation - Loss: 1.1594, CER: 0.2256, WER: 0.4713

Epoch 13 Results:
Training - Loss: 0.0963, CER: 0.0599, WER: 0.1842
Validation - Loss: 1.2324, CER: 0.2313, WER: 0.4808

Epoch 14 Results:
Training - Loss: 0.0845, CER: 0.0556, WER: 0.1747
Validation - Loss: 1.2754, CER: 0.2314, WER: 0.4801

Epoch 15 Results:
Training - Loss: 0.0787, CER: 0.0539, WER: 0.1717
Validation - Loss: 1.3185, CER: 0.2328, WER: 0.4792

Epoch 16 Results:
Training - Loss: 0.0746, CER: 0.0523, WER: 0.1682
Validation - Loss: 1.3452, CER: 0.2320, WER: 0.4860

Epoch 17 Results:
Training - Loss: 0.0694, CER: 0.0503, WER: 0.1638
Validation - Loss: 1.3739, CER: 0.2322, WER: 0.4825

Epoch 18 Results:
Training - Loss: 0.0658, CER: 0.0484, WER: 0.1598
Validation - Loss: 1.3862, CER: 0.2284, WER: 0.4732

Epoch 19 Results:
Training - Loss: 0.0627, CER: 0.0472, WER: 0.1568
Validation - Loss: 1.4398, CER: 0.2372, WER: 0.4881

Epoch 20 Results:
Training - Loss: 0.0604, CER: 0.0463, WER: 0.1539
Validation - Loss: 1.4614, CER: 0.2303, WER: 0.4745

Epoch 21 Results:
Training - Loss: 0.0579, CER: 0.0455, WER: 0.1542
Validation - Loss: 1.4843, CER: 0.2318, WER: 0.4778

Epoch 22 Results:
Training - Loss: 0.0559, CER: 0.0446, WER: 0.1509
Validation - Loss: 1.5097, CER: 0.2336, WER: 0.4821

Epoch 23 Results:
Training - Loss: 0.0556, CER: 0.0449, WER: 0.1509
Validation - Loss: 1.5417, CER: 0.2375, WER: 0.4862

Epoch 24 Results:
Training - Loss: 0.0527, CER: 0.0432, WER: 0.1472
Validation - Loss: 1.5387, CER: 0.2381, WER: 0.4899

Epoch 25 Results:
Training - Loss: 0.0493, CER: 0.0423, WER: 0.1440
Validation - Loss: 1.6057, CER: 0.2339, WER: 0.4823

Epoch 26 Results:
Training - Loss: 0.0511, CER: 0.0431, WER: 0.1484
Validation - Loss: 1.5855, CER: 0.2363, WER: 0.4843

Epoch 27 Results:
Training - Loss: 0.0465, CER: 0.0424, WER: 0.1455
Validation - Loss: 1.6309, CER: 0.2359, WER: 0.4855

Epoch 28 Results:
Training - Loss: 0.0500, CER: 0.0423, WER: 0.1451
Validation - Loss: 1.6001, CER: 0.2378, WER: 0.4852

Epoch 29 Results:
Training - Loss: 0.0482, CER: 0.0412, WER: 0.1424
Validation - Loss: 1.6598, CER: 0.2375, WER: 0.4864

Epoch 30 Results:
Training - Loss: 0.0461, CER: 0.0435, WER: 0.1506
Validation - Loss: 1.7439, CER: 0.2409, WER: 0.4957
Model saved as cnn_lstm_ctc_handwritten_v1_words_30ep_CNN-BiLSTM-CTC_CNN-VGG16_BiLSTM-1dim.pth
Time elapsed: 14856.237878084183
Start time: 1744811556.6167789
End time: 1744826412.854657
