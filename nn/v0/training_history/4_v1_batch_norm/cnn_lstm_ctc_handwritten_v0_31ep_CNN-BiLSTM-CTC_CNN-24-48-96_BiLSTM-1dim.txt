Device: cuda

Neural Network Architecture:
CNN_LSTM_CTC_V2_CNN_more_filters_batch_norm(
  (cnn): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)
  )
  (lstm): LSTM(1024, 256, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=512, out_features=80, bias=True)
)

Hyperparameters:
img_height: 32
num_channels: 1
n_classes: 80
n_h: 256
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
learning_rate: 0.001
criterion: CTCLoss()
num_epochs: 30
batch_size: 8
transform: Resize with aspect ratio
dataset: IAM Lines Dataset (writer-independent split)
Starting training process: 


Epoch 1 Results:
Training - Loss: 1.3613, CER: 0.4207, WER: 0.6403
Validation - Loss: 0.8243, CER: 0.2385, WER: 0.4863

Epoch 2 Results:
Training - Loss: 0.6348, CER: 0.1924, WER: 0.4292
Validation - Loss: 0.6618, CER: 0.1861, WER: 0.4158

Epoch 3 Results:
Training - Loss: 0.4877, CER: 0.1496, WER: 0.3634
Validation - Loss: 0.6171, CER: 0.1665, WER: 0.3841

Epoch 4 Results:
Training - Loss: 0.3982, CER: 0.1262, WER: 0.3219
Validation - Loss: 0.6166, CER: 0.1665, WER: 0.3914

Epoch 5 Results:
Training - Loss: 0.3293, CER: 0.1088, WER: 0.2889
Validation - Loss: 0.5939, CER: 0.1539, WER: 0.3636

Epoch 6 Results:
Training - Loss: 0.2740, CER: 0.0954, WER: 0.2625
Validation - Loss: 0.6146, CER: 0.1585, WER: 0.3712

Epoch 7 Results:
Training - Loss: 0.2293, CER: 0.0837, WER: 0.2382
Validation - Loss: 0.6214, CER: 0.1510, WER: 0.3621

Epoch 8 Results:
Training - Loss: 0.1956, CER: 0.0759, WER: 0.2215
Validation - Loss: 0.6559, CER: 0.1539, WER: 0.3661

Epoch 9 Results:
Training - Loss: 0.1667, CER: 0.0681, WER: 0.2036
Validation - Loss: 0.6743, CER: 0.1523, WER: 0.3655

Epoch 10 Results:
Training - Loss: 0.1443, CER: 0.0632, WER: 0.1933
Validation - Loss: 0.7219, CER: 0.1560, WER: 0.3723

Epoch 11 Results:
Training - Loss: 0.1255, CER: 0.0585, WER: 0.1826
Validation - Loss: 0.7485, CER: 0.1546, WER: 0.3724

Epoch 12 Results:
Training - Loss: 0.1136, CER: 0.0551, WER: 0.1750
Validation - Loss: 0.7853, CER: 0.1532, WER: 0.3680

Epoch 13 Results:
Training - Loss: 0.1018, CER: 0.0518, WER: 0.1669
Validation - Loss: 0.8032, CER: 0.1554, WER: 0.3714

Epoch 14 Results:
Training - Loss: 0.0916, CER: 0.0497, WER: 0.1617
Validation - Loss: 0.8274, CER: 0.1549, WER: 0.3710

Epoch 15 Results:
Training - Loss: 0.0851, CER: 0.0484, WER: 0.1589
Validation - Loss: 0.8384, CER: 0.1570, WER: 0.3719

Epoch 16 Results:
Training - Loss: 0.0794, CER: 0.0471, WER: 0.1568
Validation - Loss: 0.8865, CER: 0.1576, WER: 0.3761

Epoch 17 Results:
Training - Loss: 0.0735, CER: 0.0455, WER: 0.1519
Validation - Loss: 0.9039, CER: 0.1564, WER: 0.3768

Epoch 18 Results:
Training - Loss: 0.0698, CER: 0.0443, WER: 0.1496
Validation - Loss: 0.9139, CER: 0.1578, WER: 0.3729

Epoch 19 Results:
Training - Loss: 0.0657, CER: 0.0433, WER: 0.1473
Validation - Loss: 0.9546, CER: 0.1591, WER: 0.3794

Epoch 20 Results:
Training - Loss: 0.0620, CER: 0.0427, WER: 0.1453
Validation - Loss: 0.9859, CER: 0.1593, WER: 0.3796

Epoch 21 Results:
Training - Loss: 0.0598, CER: 0.0420, WER: 0.1430
Validation - Loss: 1.1561, CER: 0.2017, WER: 0.4401

Epoch 22 Results:
Training - Loss: 0.0646, CER: 0.0439, WER: 0.1471
Validation - Loss: 1.0254, CER: 0.1566, WER: 0.3732

Epoch 23 Results:
Training - Loss: 0.0600, CER: 0.0416, WER: 0.1421
Validation - Loss: 1.0093, CER: 0.1575, WER: 0.3761

Epoch 24 Results:
Training - Loss: 0.0474, CER: 0.0375, WER: 0.1305
Validation - Loss: 1.0392, CER: 0.1592, WER: 0.3762

Epoch 25 Results:
Training - Loss: 0.0536, CER: 0.0404, WER: 0.1392
Validation - Loss: 1.0325, CER: 0.1557, WER: 0.3721

Epoch 26 Results:
Training - Loss: 0.0519, CER: 0.0400, WER: 0.1384
Validation - Loss: 1.0619, CER: 0.1616, WER: 0.3831

Epoch 27 Results:
Training - Loss: 0.0490, CER: 0.0393, WER: 0.1372
Validation - Loss: 1.0853, CER: 0.1576, WER: 0.3789

Epoch 28 Results:
Training - Loss: 0.0503, CER: 0.0392, WER: 0.1360
Validation - Loss: 1.0881, CER: 0.1579, WER: 0.3750

Epoch 29 Results:
Training - Loss: 0.0461, CER: 0.0384, WER: 0.1337
Validation - Loss: 1.1120, CER: 0.1559, WER: 0.3739

Epoch 30 Results:
Training - Loss: 0.0448, CER: 0.0380, WER: 0.1330
Validation - Loss: 1.1171, CER: 0.1592, WER: 0.3776
Model saved as cnn_lstm_ctc_handwritten_v0_lines_30ep_CNN-BiLSTM-CTC_CNN-24-48-96_BiLSTM-1dim.pth
Time elapsed: 9870.878601074219
Start time: 1744610818.1844294
End time: 1744620689.0630305
