# Модель CNN-BiLSTM-CTC v1

Модель CNN_BiLSTM_CTC_V1 є першою повноцінною реалізацією підходу CRNN (Convolutional Recurrent Neural Network) для розпізнавання рукописного тексту в рамках нашого проєкту. Ця модель поєднує згорткові шари для екстракції візуальних ознак з двонаправленим LSTM для обробки послідовностей та CTC-декодер для розпізнавання символів.

### Архітектура моделі

CNN_BiLSTM_CTC_V1 складається з таких основних компонентів:

```
CNN_BiLSTM_CTC_V1(
  (cnn): Sequential(
    # Блок 1: 1 -> 16 каналів
    Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    ReLU()
    MaxPool2d(kernel_size=(2, 2), stride=(2, 2))
    
    # Блок 2: 16 -> 32 каналів
    Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    ReLU()
    MaxPool2d(kernel_size=(2, 2), stride=(2, 2))
  )
  (lstm): LSTM(32 * (img_height // 4), 64, bidirectional=True, batch_first=True)
  (fc): Linear(in_features=128, out_features=n_classes, bias=True)
)
```

### Ключові особливості архітектури

1. **CNN компонент**:
   - Два згорткових блоки для екстракції ознак з рукописного тексту
   - Зростаюча кількість каналів (16 → 32) для покращення репрезентації ознак
   - Max-pooling після кожного згорткового шару для зменшення просторових розмірів
   - Відсутність Batch Normalization, що обмежує стабільність навчання

2. **RNN компонент**:
   - Однорівневий двонаправлений LSTM для обробки послідовностей
   - Розмір прихованого стану 64, що забезпечує достатню виразність моделі
   - Параметр batch_first=True для зручності обробки батчів зображень

3. **Вихідний шар**:
   - Повнозв'язний шар для проекції виходу LSTM до кількості класів символів
   - Вивід softmax-вірогідностей для CTC-декодування

### Тренувальні дані та процес навчання

- **Набір даних**: IAM Words dataset
- **Стратегія розбиття**: Розбиття за авторами (writer-independent)
- **Тривалість навчання**: 45 епох
- **Розмір пакету**: 32
- **Оптимізатор**: Adam з початковою швидкістю навчання 0.001
- **Функція втрат**: CTC Loss
- **Аугментація даних**: Мінімальна (легкі афінні трансформації)

### Результати оцінки

На основі даних з evaluation_results.json:

| Метрика                       | Значення |
|-------------------------------|----------|
| Character Error Rate (CER)    | ~0.25    |
| Word Error Rate (WER)         | ~0.47    |
| Середня відстань Левенштейна  | ~0.78    |
| Точність розпізнавання слів   | ~53%     |

### Аналіз результатів та гіпотези

1. **Базова функціональність**:
   - Модель успішно реалізує парадигму CNN+RNN+CTC для розпізнавання рукописного тексту
   - Досягнуто базового рівня розпізнавання з нетривіальними результатами

2. **Обмеження CNN компонента**:
   - Невелика кількість фільтрів (16, 32) обмежує здатність виділяти складні ознаки
   - Відсутність Batch Normalization призводить до нестабільності в навчанні
   - Лише два згорткових блоки недостатньо для ієрархічної екстракції ознак

3. **Обмеження RNN компонента**:
   - Однорівневий LSTM обмежує здатність моделювати складні залежності
   - Розмір прихованого стану 64 може бути недостатнім для повної репрезентації контексту

### Обмеження моделі

1. **Проблеми з варіативністю почерку**:
   - Модель часто помиляється на нетипових або складних зразках почерку
   - Обмежена здатність узагальнювати на різні стилі письма

2. **Складності з контекстом**:
   - Проблеми з розпізнаванням слів, де контекст критично важливий
   - Високий рівень WER порівняно з CER вказує на проблеми з цілісним розпізнаванням слів

3. **Технічні обмеження**:
   - Відсутність регуляризації призводить до перенавчання на пізніх епохах
   - Нестабільність градієнтів через відсутність нормалізації

### Висновки та рекомендації

Модель v1 представляє першу функціональну реалізацію підходу CRNN для розпізнавання рукописного тексту. Хоча її продуктивність обмежена, вона забезпечує базовий рівень розпізнавання та встановлює основу для подальших удосконалень.

Основні напрямки для покращення:

1. Впровадження Batch Normalization для стабілізації навчання
2. Збільшення кількості та розміру фільтрів у згорткових шарах
3. Розширення RNN компонента (більший розмір прихованого стану, більше шарів)
4. Удосконалення стратегії об'єднання для збереження просторової інформації
5. Впровадження додаткових методів регуляризації для запобігання перенавчанню