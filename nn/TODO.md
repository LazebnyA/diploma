### Фікс помилок з даними

Окрема частина про обробку даних - очищення даних від неправильно маркованих прикладів.

- [ ] Зробити аналогічні дії уже зробленим:

Було зроблене дослідження зображень з найбільшою шириною. Серед таких зобрежень виявлялись аномальні - вони маркувались короткими словами, а на них сами були зображені цілі речення. 

___

Інше:
- [ ] Розробити порівняння кількості фільтрів і n_h одночасно, оскільки чим більше фільтрів - тим більше ознак вилучається, і тим більше ознак потрібно передавати між часовими кроками в h_t

- [ ] Переробити схеми, щоб було видно, що кожен часовий крок LSTM відповідає за передбачення свого символа.

___

### Базова модель

- [x] Переробити саму початкову модель - взяти як початкову - модель з maxpool (2, 2) на другому шарі CNN. 
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [x] Порівняння для оптимізаторів та lr
  - [x] Порівняння для розмірів батчів
    - Було обрано 8, оскільки показав найкращі результати  по метрикам + швидкодії
  - [ ] Порівняти окремо для кількості фільтрів та для кількості n_h
  - [x] Порівняти разом для кількості фільтрів та для кількості n_h
  - [ ] Порівняти для кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі

___

### Глибша CNN - VGG16 подібна архітектура

- [ ] Збільшити глибину, порівняти з базовою моделлю.
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [ ] Порівняння для оптимізаторів та lr
  - [ ] Порівняння для розмірів батчів
  - [ ] Порівняння для кількості фільтрів
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі
  
___

### ResNet18 подібна архітектура

- [x] Натренувати на базових гіперпараметрах
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [x] Порівняння для оптимізаторів та lr
    - Обрано RMSprop з learning rate = 0.0001
  - [x] Порівняння для розмірів батчів
    - Обрано розмір = 16, оскільки забезпечує точність + швидкодію
  - [x] Порівняння для кількості фільтрів
    - Найкраще себе показав результат з кількістю фільтрів 48, що відповідає 48-96-192-274
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Було вирішено зупинитися на n_h = 512, оскільки різниця по часу від 256 дуже мала, а різниця по точності велика, а для 1024 різниця по часу дуже велика.
    - 
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі

___

### Data Preprocessing

- [ ] Для моделей - порівнюємо техніки препроцесінгу, спочатку ходу навчання моделей з техніками, потім на самописному наборі.
- [ ] Після цього порівнюємо те ж саме з аугментацією даних.

___

### Data Postprocessing (Опціонально)

- [ ] Для моделей - порівнюємо техніки постпроцесінгу

___