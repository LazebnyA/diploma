### Фікс помилок з даними

Окрема частина про обробку даних - очищення даних від неправильно маркованих прикладів.

- [ ] Зробити аналогічні дії уже зробленим:

Було зроблене дослідження зображень з найбільшою шириною. Серед таких зобрежень виявлялись аномальні - вони маркувались короткими словами, а на них сами були зображені цілі речення. 

___

### Базова модель

- [x] Переробити саму початкову модель - взяти як початкову - модель з maxpool (2, 2) на другому шарі CNN. 
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [x] Порівняння для оптимізаторів та lr
    - Обраний Адам - 0.001
  - [x] Порівняння для розмірів батчів
    - Було обрано розмір 32 
  - [x] Порівняння для розмірів зображень
    - Для даної моделі було обрано 32
  - [x] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [x] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для найбільш оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі


*Додатково*:
- [ ] Перетренувати тюнінг на img_height з метою отримання середнього часу навчання на епоху.

___

### Архітектура CNN і BiLSTM

- [x] Збільшити глибину, порівняти з базовою моделлю.  
  - Модель не навчається.
- [ ] Знайти методом підбору модель, яка буде навчатися.
- [ ] Збільшити кількість фільтрів, порівняти з базовою моделлю, вибрати оптимальний варіант.
  - [ ] Порівняти для розмірів зображень
  - [ ] Обраний параметр n_h для висоти 32 в залежності від висоти зображення робити більшим і порівняти
- [ ] Додати нормалізацію батчів
- [ ] Порівняти для параметрів n_h та кількості шарів LSTM
- [ ] Опціонально. Порівняти батч сайзи.

___

### Data Preprocessing


- [ ] Порівнюємо перформанс моделей для гнучкого підходу навчання та для навчання на прикладах з фіксованими висотою та шириною.
- [ ] Для нинішньої моделі - порівнюємо техніки препроцесінгу, спочатку ходу навчання моделей з техніками, потім на самописному наборі.
- [ ] Після цього порівнюємо те ж саме з аугментацією даних.

___

### Адаптація відомих CNN моделей під задачу (додатково)

(VGG16, ResNet, EfficientNet)

- [ ] 

___