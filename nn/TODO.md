### Інше:

- [x] Розробити порівняння кількості фільтрів і n_h одночасно, оскільки чим більше фільтрів - тим більше ознак вилучається, і тим більше ознак потрібно передавати між часовими кроками в h_t.

- [ ] Переробити схеми, щоб було видно, що кожен часовий крок LSTM відповідає за передбачення свого символа. 
 
### Пріоритетні

- [ ] Навчити заново модель v0 для різної кількості шарів LSTM і вставити графіки.

- [ ] Переробити блок з аугментацією/препроцесингом.

- [ ] Розробити схему моделі ResNet.

- [ ] Дописати блок про математичне забезпечення ResNet.

- [ ] Перенести схеми та опис НН до блоку математичне забезпечення, в описі програмного залишити лише хід навчання моделей.

### Додатково

- [ ] Розроби невеликий історичний датасет на основі Washington і Bentham

- [ ] Додати датасет для друкованого тексту і перевірити перформанс на ньому

___

### Базова модель

- [x] Переробити саму початкову модель - взяти як початкову - модель з maxpool (2, 2) на другому шарі CNN. 
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [x] Порівняння для оптимізаторів та lr
  - [x] Порівняння для розмірів батчів
    - Було обрано 8, оскільки показав найкращі результати по метрикам + швидкодії
  - [x] Порівняти окремо для кількості фільтрів та для кількості n_h
  - [x] Порівняти разом для кількості фільтрів та для кількості n_h
  - [x] Порівняти для кількості шарів LSTM
  - [x] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі і на саморобному.

- [ ] Поглибити модель, проаналізувати вплив додавання технік регуляризації - нормалізації батчів, дропауту.   

___

### Глибша CNN - VGG16 подібна архітектура (якщо буде час (в останню чергу))

- [ ] Збільшити глибину, порівняти з базовою моделлю.
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [ ] Порівняння для оптимізаторів та lr
  - [ ] Порівняння для розмірів батчів
  - [ ] Порівняння для кількості фільтрів
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі
  
___

### ResNet18 подібна архітектура

- [x] Натренувати на базових гіперпараметрах
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [x] Порівняння для оптимізаторів та lr
    - Обрано RMSprop з learning rate = 0.0001
  - [x] Порівняння для розмірів батчів
    - Обрано розмір = 16, оскільки забезпечує точність + швидкодію
  - [x] Порівняння для кількості фільтрів
    - Найкраще себе показав результат з кількістю фільтрів 48, що відповідає 48-96-192-274
  - [x] Порівняти для параметрів n_h та кількості шарів LSTM
    - Було вирішено зупинитися на n_h = 1024, та кількості фільтрів 64. Оскільки така комбінація забезпечує найвищу точність та швидкість навчання (по епохах, але не по часу).
  - [x] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі

___

### Data Preprocessing


___

### Data Postprocessing (Опціонально)

- [ ] Для моделей - порівнюємо техніки постпроцесінгу

___