### Фікс помилок з даними

Окрема частина про обробку даних - очищення даних від неправильно маркованих прикладів.

- [ ] Зробити аналогічні дії уже зробленим:

Було зроблене дослідження зображень з найбільшою шириною. Серед таких зобрежень виявлялись аномальні - вони маркувались короткими словами, а на них сами були зображені цілі речення. 

___

### Базова модель

- [x] Переробити саму початкову модель - взяти як початкову - модель з maxpool (2, 2) на другому шарі CNN. 
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [ ] Порівняння для оптимізаторів та lr
  - [ ] Порівняння для розмірів батчів
  - [ ] Порівняння для кількості фільтрів
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі

___

### Глибша CNN - VGG16 подібна архітектура

- [ ] Збільшити глибину, порівняти з базовою моделлю.
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [ ] Порівняння для оптимізаторів та lr
  - [ ] Порівняння для розмірів батчів
  - [ ] Порівняння для кількості фільтрів
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі
  
___

### ResNet18 подібна архітектура

- [ ] Натренувати на базових гіперпараметрах
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [ ] Порівняння для оптимізаторів та lr
  - [ ] Порівняння для розмірів батчів
  - [ ] Порівняння для кількості фільтрів
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі

___

### EfficientNet подібна архітектура

- [ ] Натренувати на базових гіперпараметрах
- [ ] Зробити порівняння для різних гіперпараметрів уже з обраною версією.
  - [ ] Порівняння для оптимізаторів та lr
  - [ ] Порівняння для розмірів батчів
  - [ ] Порівняння для кількості фільтрів
  - [ ] Порівняти для параметрів n_h та кількості шарів LSTM
    - Як `n_h` було обрано 512 через найкращу стабільність навчання, та значення метрик на вал. вибірці. При тому, що середній час навчання за епоху займав такий самий час як і для інших
  - [ ] Порівняти для 1-шарової та 2-шарової BiLSTM
  - [ ] Натренувати модель для оптимальної епохи - де лосс на валідаційному наборі найменший і далі лосс збільшується.
  - [ ] Затестити перформанс моделі на тестовому наборі

___

### Data Preprocessing

- [ ] Для моделей - порівнюємо техніки препроцесінгу, спочатку ходу навчання моделей з техніками, потім на самописному наборі.
- [ ] Після цього порівнюємо те ж саме з аугментацією даних.

___

### Data Postprocessing (Опціонально)

- [ ] Для моделей - порівнюємо техніки постпроцесінгу

___