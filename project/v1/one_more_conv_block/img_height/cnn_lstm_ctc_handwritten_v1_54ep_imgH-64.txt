Device: cuda

Neural Network Architecture:
CNN_LSTM_CTC_V2(
  (cnn): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)
    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)
  )
  (lstm): LSTM(2048, 256, batch_first=True)
  (fc): Linear(in_features=256, out_features=80, bias=True)
)

Hyperparameters:
img_height: 64
num_channels: 1
n_classes: 80
n_h: 256
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
learning_rate: 0.001
criterion: CTCLoss()
num_epochs: 75
batch_size: 8
transform: Resize with aspect ratio and ToTensor
Starting training process: 

Epoch 1 completed. Training Loss: 2.0171, Validation Loss: 1.1056
Epoch 2 completed. Training Loss: 1.0539, Validation Loss: 0.7832
Epoch 3 completed. Training Loss: 0.8409, Validation Loss: 0.6773
Epoch 4 completed. Training Loss: 0.7325, Validation Loss: 0.6247
Epoch 5 completed. Training Loss: 0.6574, Validation Loss: 0.5857
Epoch 6 completed. Training Loss: 0.5985, Validation Loss: 0.5535
Epoch 7 completed. Training Loss: 0.5527, Validation Loss: 0.5219
Epoch 8 completed. Training Loss: 0.5072, Validation Loss: 0.5023
Epoch 9 completed. Training Loss: 0.4728, Validation Loss: 0.5257
Epoch 10 completed. Training Loss: 0.4371, Validation Loss: 0.5424
Epoch 11 completed. Training Loss: 0.4083, Validation Loss: 0.4707
Epoch 12 completed. Training Loss: 0.3808, Validation Loss: 0.5162
Epoch 13 completed. Training Loss: 0.3596, Validation Loss: 0.5099
Epoch 14 completed. Training Loss: 0.3396, Validation Loss: 0.4940
Epoch 15 completed. Training Loss: 0.3264, Validation Loss: 0.5174
Epoch 16 completed. Training Loss: 0.3018, Validation Loss: 0.5258
Epoch 17 completed. Training Loss: 0.2859, Validation Loss: 0.5566
Epoch 18 completed. Training Loss: 0.2751, Validation Loss: 0.5224
Epoch 19 completed. Training Loss: 0.2590, Validation Loss: 0.5304
Epoch 20 completed. Training Loss: 0.2491, Validation Loss: 0.5351
Epoch 21 completed. Training Loss: 0.2352, Validation Loss: 0.5669
Epoch 22 completed. Training Loss: 0.2200, Validation Loss: 0.5955
Epoch 23 completed. Training Loss: 0.2138, Validation Loss: 0.5672
Epoch 24 completed. Training Loss: 0.2054, Validation Loss: 0.5532
Epoch 25 completed. Training Loss: 0.1932, Validation Loss: 0.5935
Epoch 26 completed. Training Loss: 0.2029, Validation Loss: 0.5993
Epoch 27 completed. Training Loss: 0.1847, Validation Loss: 0.6162
Epoch 28 completed. Training Loss: 0.1834, Validation Loss: 0.6092
Epoch 29 completed. Training Loss: 0.1758, Validation Loss: 0.6253
Epoch 30 completed. Training Loss: 0.1662, Validation Loss: 0.6289
Epoch 31 completed. Training Loss: 0.1608, Validation Loss: 0.6194
Epoch 32 completed. Training Loss: 0.1570, Validation Loss: 0.6556
Epoch 33 completed. Training Loss: 0.1583, Validation Loss: 0.6346
Epoch 34 completed. Training Loss: 0.1555, Validation Loss: 0.6492
Epoch 35 completed. Training Loss: 0.1437, Validation Loss: 0.6666
Epoch 36 completed. Training Loss: 0.1425, Validation Loss: 0.6942
Epoch 37 completed. Training Loss: 0.1441, Validation Loss: 0.7233
Epoch 38 completed. Training Loss: 0.1385, Validation Loss: 0.7294
Epoch 39 completed. Training Loss: 0.1404, Validation Loss: 0.6819
Epoch 40 completed. Training Loss: 0.1320, Validation Loss: 0.7058
Epoch 41 completed. Training Loss: 0.1319, Validation Loss: 0.6879
Epoch 42 completed. Training Loss: 0.1248, Validation Loss: 0.7747
Epoch 43 completed. Training Loss: 0.1254, Validation Loss: 0.7263
Epoch 44 completed. Training Loss: 0.1233, Validation Loss: 0.7565
Epoch 45 completed. Training Loss: 0.1297, Validation Loss: 0.7241
Epoch 46 completed. Training Loss: 0.1222, Validation Loss: 0.7170
Epoch 47 completed. Training Loss: 0.1156, Validation Loss: 0.7647
Epoch 48 completed. Training Loss: 0.1156, Validation Loss: 0.7842
Epoch 49 completed. Training Loss: 0.1160, Validation Loss: 0.7555
Epoch 50 completed. Training Loss: 0.1151, Validation Loss: 0.7625
Epoch 51 completed. Training Loss: 0.1140, Validation Loss: 0.7764
Epoch 52 completed. Training Loss: 0.1128, Validation Loss: 0.7646
Epoch 53 completed. Training Loss: 0.1014, Validation Loss: 0.7600
Training interrupted by user.
Model saved as cnn_lstm_ctc_handwritten_v2_54ep_imgH-64.pth
